# -*- coding: utf-8 -*-
"""CointegrationTest.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ihKxzKeMQCMiHwmrBvL5ITT3eR07MvDV
"""

import numpy as np
import pandas as pd
import yfinance as yf
from statsmodels.tsa.stattools import coint
import matplotlib.pyplot as plt

# Load stock data
stock1 = 'BRK-B'
stock2 = 'NVDA'
start_date = "2021-01-01"
end_date = "2025-02-01"

# Download historical price data
data1 = yf.download(stock1, start=start_date, end=end_date)['Close']
data2 = yf.download(stock2, start=start_date, end=end_date)['Close']

# Align the data
df = pd.concat([data1, data2], axis=1).dropna()
df.columns = [stock1, stock2]

# Perform the Engle-Granger Cointegration Test
score, p_value, _ = coint(df[stock1], df[stock2])

# Print results
print(f"Cointegration Test Results for {stock1} & {stock2}:")
print(f"Test Statistic: {score:.4f}")
print(f"P-Value: {p_value:.4f}")

# Plot the spread (if cointegrated, should revert to mean)
spread = df[stock1] - df[stock2]
plt.figure(figsize=(10,5))
plt.plot(spread, label="Spread")
plt.axhline(spread.mean(), color='red', linestyle='dashed', label="Mean")
plt.legend()
plt.title(f"Spread Between {stock1} and {stock2}")
plt.show()

# Decision rule: If p-value < 0.05, we reject Hâ‚€ and confirm cointegration.
if p_value < 0.05:
    print("âœ… The stocks are COINTEGRATED. Good for pairs trading!")
else:
    print("âŒ No strong evidence of cointegration.")

import yfinance as yf
import datetime as dt
import pandas as pd
import numpy as np
from statsmodels.tsa.stattools import coint
import matplotlib.pyplot as plt

start_time = dt.datetime(2021, 1, 1)
end_time = dt.datetime.now() - dt.timedelta(days=1)
data1 = yf.download("KO", start_time, end_time)['Close']
data2 = yf.download("PEP", start_time, end_time)['Close']

df = pd.concat([data1, data2], axis = 1).dropna()
df.columns = ["KO", "PEP"]
score, p_value, _ = coint(df["KO"],df["PEP"])
print(p_value)

import yfinance as yf
import pandas as pd
import itertools
from statsmodels.tsa.stattools import coint

# Step 1: Define Cryptos to Analyze (Top 100)
crypto_list = [
    # ðŸ”¹ Tech Stocks (Correlated companies, competitors)
    "NVDA",  # Nvidia (GPU, AI computing)
    "AMD",  # Advanced Micro Devices (GPU & CPU competitor to Nvidia)
    "MSFT",  # Microsoft (Cloud, AI)
    "GOOGL",  # Alphabet (AI, Cloud)
    "AAPL",  # Apple (Tech giant, high liquidity)
    "AMZN",  # Amazon (Cloud, e-commerce)

    # ðŸ”¹ Crypto (Highly correlated, good for statistical arbitrage)
    "ETH-USD",  # Ethereum (Smart contracts)
    "BNB-USD",  # Binance Coin (Exchange token)
    "SOL-USD",  # Solana (High-speed blockchain)
    "XRP-USD",  # Ripple (Cross-border payments)
    "ADA-USD",  # Cardano (Ethereum competitor)
    "DOGE-USD",  # Dogecoin (Meme coin, correlated with Elon Musk-related assets)
    "MATIC-USD",  # Polygon (Layer 2 Ethereum scaling solution)
    "LTC-USD",  # Litecoin (Bitcoin fork with faster transactions)

    # ðŸ”¹ Financials (Good for tracking macro trends)
    "BRK-B",  # Berkshire Hathaway (Diversified financials)
    "JPM",  # JPMorgan Chase (Banking)
    "GS",  # Goldman Sachs (Investment banking, trading)

    # ðŸ”¹ Energy & Industrials (Macroeconomic trend pairs)
    "XOM",  # ExxonMobil (Oil & Gas)
    "CVX",  # Chevron (Oil & Gas)

    # ðŸ”¹ ETFs (For hedging & sector-based stat arb)
    "XLK",  # Technology Select Sector ETF (Tech exposure)
    "SPY"   # S&P 500 ETF (Benchmark for large-cap US stocks)
]

# Step 2: Download Historical Prices
def get_crypto_data(tickers, start="2021-01-01", end="2025-02-01"):
    data = yf.download(tickers, start=start, end=end)['Close']
    return data

# Step 3: Test Cointegration on All Pairs
def find_cointegrated_pairs(data):
    pairs = list(itertools.combinations(data.columns, 2))
    results = []

    for crypto1, crypto2 in pairs:
        series1 = data[crypto1].dropna()
        series2 = data[crypto2].dropna()

        if len(series1) > 200 and len(series2) > 200:  # Ensure enough data points
            combined = pd.concat([series1, series2], axis=1).dropna()
            if len(combined) > 200:
                score, p_value, _ = coint(combined.iloc[:, 0], combined.iloc[:, 1])
                results.append((crypto1, crypto2, p_value))

    # Sort by lowest p-value (strongest cointegration)
    results.sort(key=lambda x: x[2])
    return results

# Step 4: Run the Pipeline
crypto_data = get_crypto_data(crypto_list)
cointegrated_pairs = find_cointegrated_pairs(crypto_data)

# Step 5: Convert Results to DataFrame and Display Best Pairs
df_results = pd.DataFrame(cointegrated_pairs, columns=["Crypto 1", "Crypto 2", "p-value"])
print(df_results.head(20))  # Show top 20 most cointegrated pairs

# Import necessary libraries
import numpy as np
import pandas as pd
import yfinance as yf
from statsmodels.tsa.stattools import coint
import matplotlib.pyplot as plt
import datetime as dt

# Define the time period for historical data
start_date = dt.datetime(2010, 1, 1)
end_date = dt.datetime.now() - dt.timedelta(days=1)

# Step 1: Download Historical Data for DOGE-USD and XRP-USD
doge_data = yf.download('NVDA', start=start_date, end=end_date)
xrp_data = yf.download('BRK-B', start=start_date, end=end_date)

# Check what columns are available in each download
print("DOGE-USD Data Columns:", doge_data.columns)
print("XRP-USD Data Columns:", xrp_data.columns)

# Use 'Adj Close' if available, otherwise fall back to 'Close'
if 'Adj Close' in doge_data.columns:
    doge = doge_data['Adj Close']
else:
    doge = doge_data['Close']

if 'Adj Close' in xrp_data.columns:
    xrp = xrp_data['Adj Close']
else:
    xrp = xrp_data['Close']

# Step 2: Combine the Data into a Single DataFrame
data = pd.concat([doge, xrp], axis=1)
data.columns = ['DOGE', 'XRP']
data.dropna(inplace=True)
print("Combined Data Shape:", data.shape)

# Step 3: Test for Cointegration
score, p_value, _ = coint(data['DOGE'], data['XRP'])
print(f'Cointegration test p-value: {p_value}')

# Step 4: Calculate the Hedge Ratio, Spread, and Z-Score
# Compute the hedge ratio using a simple linear regression (slope)
hedge_ratio = np.polyfit(data['DOGE'], data['XRP'], 1)[0]
data['Spread'] = data['XRP'] - hedge_ratio * data['DOGE']

# Compute the z-score of the spread
spread_mean = data['Spread'].mean()
spread_std = data['Spread'].std()
data['Z-Score'] = (data['Spread'] - spread_mean) / spread_std

# Step 5: Define Trading Signals Based on the Z-Score
entry_threshold = 2
exit_threshold = 1

# Initialize positions: +1 for long, -1 for short, 0 for no position
data['Position'] = 0
data.loc[data['Z-Score'] < -entry_threshold, 'Position'] = 1   # Long when spread is significantly low
data.loc[data['Z-Score'] > entry_threshold, 'Position'] = -1   # Short when spread is significantly high
data.loc[data['Z-Score'].abs() < exit_threshold, 'Position'] = 0 # Exit when close to the mean

# Forward fill positions to maintain the last signal until a new signal is generated
data['Position'] = data['Position'].replace(to_replace=0, method='ffill')

# Step 6: Backtest the Strategy
# Calculate the daily percentage change of the spread (as a proxy for returns)
data['Spread Returns'] = data['Spread'].pct_change()

# Compute the strategy returns: yesterday's position * today's spread return
data['Strategy Returns'] = data['Position'].shift(1) * data['Spread Returns']

# Calculate cumulative returns
data['Cumulative Returns'] = (1 + data['Strategy Returns']).cumprod()

# Calculate the Annualized Sharpe Ratio (assume risk-free rate = 0)
# For daily returns, annualization factor is sqrt(252)
strategy_returns = data['Strategy Returns'].dropna()
sharpe_ratio = (strategy_returns.mean() / strategy_returns.std()) * np.sqrt(252)
print("Annualized Sharpe Ratio:", sharpe_ratio)

# Plot the cumulative returns
plt.figure(figsize=(12, 6))
plt.plot(data.index, data['Cumulative Returns'], label='Strategy Cumulative Returns')
plt.title('Cumulative Returns: DOGE-USD & XRP-USD Mean Reversion Strategy')
plt.xlabel('Date')
plt.ylabel('Cumulative Returns')
plt.legend()
plt.grid(True)
plt.show()

# Print the first few rows to inspect the resulting DataFrame
print(data.head())