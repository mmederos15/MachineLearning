# -*- coding: utf-8 -*-
"""NLOPEsssaYYY.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S8LYXAOFzp2Eof0HtKmAHDuM-JFHhRma
"""

import pandas as pd
import numpy as np
import re
import string
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# --- 1. Read the CSV file ---
csv_path = 'classexampleOpenAI.csv'
df = pd.read_csv(csv_path)
print("Dataset Preview:")
print(df.head(), "\n")
print("Columns found:", df.columns.tolist(), "\n")

# --- 2. Auto-detect columns ---
# Determine the text column from keywords like 'essay', 'text', or 'content'
text_candidates = [col for col in df.columns if any(keyword in col.lower() for keyword in ['essay', 'text', 'content'])]
if text_candidates:
    text_col = text_candidates[0]
else:
    raise ValueError("No suitable text column found. Ensure your CSV has a column with 'essay', 'text', or 'content'.")

# Determine the teacher label column using keywords (e.g., 'teacher')
label_candidates = [col for col in df.columns if any(keyword in col.lower() for keyword in ['teacher'])]
if label_candidates:
    label_col = label_candidates[0]
else:
    raise ValueError("No suitable teacher column found. Ensure your CSV has a column with 'teacher'.")

print("Selected text column:", text_col)
print("Selected label column:", label_col, "\n")

# --- 3. Handle Missing Values ---
# Replace missing text and teacher values with empty strings.
df[text_col] = df[text_col].fillna("")
df[label_col] = df[label_col].fillna("")

# --- 4. Clean the Data ---
def clean_text(text):
    """Lowercase the text, remove punctuation, and collapse extra whitespace."""
    text = text.lower()
    text = re.sub(r'[' + re.escape(string.punctuation) + ']', ' ', text)
    text = re.sub(r'\s+', ' ', text)
    return text.strip()

def clean_teacher(teacher):
    """Lowercase teacher names, strip whitespace, and remove periods to merge similar labels."""
    teacher = teacher.lower().strip()
    teacher = teacher.replace('.', '')
    return teacher

# Clean the essay text.
df['clean_text'] = df[text_col].astype(str).apply(clean_text)
# Clean and standardize teacher labels.
df['clean_teacher'] = df[label_col].astype(str).apply(clean_teacher)

print("Teacher label distribution (after cleaning):")
print(df['clean_teacher'].value_counts(), "\n")

# --- 5. Merge Teacher Labels with Low Frequency ---
# Merge any teacher label with fewer than 2 samples into a common "other" class.
teacher_counts = df['clean_teacher'].value_counts()
small_labels = teacher_counts[teacher_counts < 2].index.tolist()
df['final_teacher'] = df['clean_teacher'].apply(lambda x: 'other' if x in small_labels else x)

print("Teacher label distribution (after merging small classes):")
print(df['final_teacher'].value_counts(), "\n")

# --- 6. Feature Extraction with TF-IDF ---
# Use both unigrams and bigrams to capture additional context.
vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2))
X = vectorizer.fit_transform(df['clean_text'])
y = df['final_teacher']

# --- 7. Stratified Train-Test Split ---
# We use stratification to preserve the class distribution.
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

# --- 8. Model Training ---
# Train a Logistic Regression classifier.
model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

# --- 9. Evaluation ---
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Model Accuracy: {:.2f}".format(accuracy))
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# --- 10. Exploratory Analysis: Top TF-IDF Features per Teacher ---
# For Logistic Regression, each class has a coefficient vector.
feature_names = vectorizer.get_feature_names_out()
top_n = 10  # Number of top features to display per teacher
print("Top TF-IDF features for each teacher label:")
for idx, teacher in enumerate(model.classes_):
    coef = model.coef_[idx]
    top_indices = np.argsort(coef)[-top_n:]
    top_features = feature_names[top_indices]
    print(f"Teacher: {teacher}")
    print("Top features:", top_features)
    print()